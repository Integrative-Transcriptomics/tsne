{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "from functools import partial\n",
    "from jax import vmap\n",
    "from jax.lax import scan\n",
    "from jax.lax import cond\n",
    "from jax import random\n",
    "from jax import jit\n",
    "from jax import jacrev\n",
    "from jax.lax import stop_gradient\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import manifold, datasets\n",
    "import seaborn as sns\n",
    "import jax\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "import jax.numpy as np\n",
    "from utils import MidpointNormalize, load_data\n",
    "from jax import random, flatten_util, vjp, jvp, custom_vjp, jacfwd, jacrev, vmap, grad\n",
    "from IFD_tsne import tsne_fwd\n",
    "import jax\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Finding 90 nearest neighbors using Annoy approximate search using euclidean distance...\n",
      "   --> Time elapsed: 0.03 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Running optimization with exaggeration=12.00, lr=200.00 for 250 iterations...\n",
      "Iteration   50, KL divergence 1.7257, 50 iterations in 0.2876 sec\n",
      "Iteration  100, KL divergence 1.7844, 50 iterations in 0.3822 sec\n",
      "Iteration  150, KL divergence 1.7430, 50 iterations in 0.3033 sec\n",
      "Iteration  200, KL divergence 1.7834, 50 iterations in 0.2805 sec\n",
      "Iteration  250, KL divergence 1.7445, 50 iterations in 0.2678 sec\n",
      "   --> Time elapsed: 1.52 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=200.00 for 750 iterations...\n",
      "Iteration   50, KL divergence 0.5615, 50 iterations in 0.2973 sec\n",
      "Iteration  100, KL divergence 0.5444, 50 iterations in 0.2792 sec\n",
      "Iteration  150, KL divergence 0.5187, 50 iterations in 0.2729 sec\n",
      "Iteration  200, KL divergence 0.5154, 50 iterations in 0.3176 sec\n",
      "Iteration  250, KL divergence 0.5146, 50 iterations in 0.3689 sec\n",
      "Iteration  300, KL divergence 0.4999, 50 iterations in 0.2933 sec\n",
      "Iteration  350, KL divergence 0.4995, 50 iterations in 0.4668 sec\n",
      "Iteration  400, KL divergence 0.4995, 50 iterations in 0.2920 sec\n",
      "Iteration  450, KL divergence 0.4991, 50 iterations in 0.2980 sec\n",
      "Iteration  500, KL divergence 0.4987, 50 iterations in 0.2909 sec\n",
      "Iteration  550, KL divergence 0.4988, 50 iterations in 0.2763 sec\n",
      "Iteration  600, KL divergence 0.4988, 50 iterations in 0.2740 sec\n",
      "Iteration  650, KL divergence 0.4987, 50 iterations in 0.2753 sec\n",
      "Iteration  700, KL divergence 0.4986, 50 iterations in 0.2851 sec\n",
      "Iteration  750, KL divergence 0.4987, 50 iterations in 0.2847 sec\n",
      "   --> Time elapsed: 4.57 seconds\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(127)\n",
    "key = random.PRNGKey(41)\n",
    "#X = onp.array(random.normal(key, shape=(50, 50)))\n",
    "y_guess = random.normal(key, shape=(X.shape[0], 2))\n",
    "#Y_star = TSNE(n_components=2, learning_rate=200, init=onp.array(y_guess), perplexity=30).fit_transform(X)\n",
    "Y_star = tsne_fwd(X, y_guess)\n",
    "\n",
    "X_flat, X_unflattener = flatten_util.ravel_pytree(X)   # row-wise\n",
    "Y_flat, Y_unflattener = flatten_util.ravel_pytree(Y_star) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSoftmax(x):\n",
    "    \"\"\"Compute softmax for vector x.\"\"\"\n",
    "    max_x = np.max(x)\n",
    "    exp_x = np.exp(x - max_x)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    log_sum_exp_x = np.log(sum_exp_x)\n",
    "    max_plus_log_sum_exp_x = max_x + log_sum_exp_x\n",
    "    log_probs = x - max_plus_log_sum_exp_x\n",
    "\n",
    "    # Recover probs\n",
    "    exp_log_probs = np.exp(log_probs)\n",
    "    sum_log_probs = np.sum(exp_log_probs)\n",
    "    probs = exp_log_probs / sum_log_probs\n",
    "    return probs\n",
    "\n",
    "def Hbeta(D: np.ndarray, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the log2(perplexity)=Entropy and the P-row (P_i) for a specific value of the\n",
    "        precision=1/(sigma**2) (beta) of a Gaussian distribution. D: vector of squared Euclidean distances (without i)\n",
    "    :param D: vector of length d, squared Euclidean distances to all other datapoints (except itself)\n",
    "    :param beta: precision = beta = 1/sigma**2\n",
    "    :return: H: log2(Entropy), P: computed probabilites\n",
    "    \"\"\"\n",
    "    # TODO: exchange by softmax as described by https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/\n",
    "    P = np.exp(-D * beta)     # numerator of p j|i\n",
    "    sumP = np.sum(P, axis=None)    # denominator of p j|i --> normalization factor\n",
    "    new_P = logSoftmax(-D * beta)\n",
    "    sumP += 1e-8\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    return H, new_P\n",
    "\n",
    "def Hbeta_final(D: np.ndarray, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the log2(perplexity)=Entropy and the P-row (P_i) for a specific value of the\n",
    "        precision=1/(sigma**2) (beta) of a Gaussian distribution. D: vector of squared Euclidean distances (without i)\n",
    "    :param D: vector of length d, squared Euclidean distances to all other datapoints (except itself)\n",
    "    :param beta: precision = beta = 1/sigma**2\n",
    "    :return: H: log2(Entropy), P: computed probabilites\n",
    "    \"\"\"\n",
    "    # TODO: exchange by softmax as described by https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/\n",
    "    P = np.exp(-D * beta)     # numerator of p j|i\n",
    "    sumP = np.sum(P, axis=None)    # denominator of p j|i --> normalization factor\n",
    "    sumP += 1e-8\n",
    "    new_P = P/sumP\n",
    "    return new_P\n",
    "\n",
    "def HdiffGreaterTrue(*betas):\n",
    "    beta, betamax = betas\n",
    "    return beta*2\n",
    "\n",
    "def HdiffGreaterFalse(*betas):\n",
    "    beta, betamax = betas\n",
    "    return (beta+betamax)/2\n",
    "\n",
    "def HdiffSmallerTrue(*betas):\n",
    "    beta, betamin = betas\n",
    "    return beta/2\n",
    "\n",
    "def HdiffSmallerFalse(*betas):\n",
    "    beta, betamin = betas\n",
    "    return (beta+betamin)/2\n",
    "\n",
    "def HdiffGreater(*betas):\n",
    "    beta, betamin, betamax = betas\n",
    "    betamin = beta\n",
    "    beta = cond((np.logical_or(betamax == np.inf, betamax == -np.inf)), HdiffGreaterTrue, HdiffGreaterFalse, *(beta, betamax))\n",
    "    return beta, betamin, betamax\n",
    "\n",
    "def HdiffSmaller(*betas):\n",
    "    beta, betamin, betamax = betas\n",
    "    betamax = beta\n",
    "    beta = cond(np.logical_or(betamin == np.inf, betamin == -np.inf), HdiffSmallerTrue, HdiffSmallerFalse, *(beta, betamin))\n",
    "    return beta, betamin, betamax\n",
    "\n",
    "def HdiffGreaterTolerance(*betas):\n",
    "    beta, betamin, betamax, Hdiff = betas\n",
    "    beta, betamin, betamax = cond(Hdiff > 0, HdiffGreater, HdiffSmaller, *(beta, betamin, betamax))\n",
    "    return beta, betamin, betamax, Hdiff\n",
    "\n",
    "def binarySearch(res, el, Di, logU):\n",
    "    print('Entered binary search function')\n",
    "    Hdiff, thisP, beta, betamin, betamax = res\n",
    "    beta, betamin, betamax, Hdiff = cond(np.abs(Hdiff) < 1e-5, lambda a, b, c, d: (a, b, c, d), HdiffGreaterTolerance, *(beta, betamin, betamax, Hdiff))\n",
    "    (H, thisP) = Hbeta(Di, beta)\n",
    "    Hdiff = H - logU\n",
    "    return (Hdiff, thisP, beta, betamin, betamax), el\n",
    "\n",
    "def x2beta_inner(Di: np.ndarray, iterator, beta, betamin, betamax, perplexity=30, tol=1e-5):\n",
    "    \"\"\"\n",
    "    binary search for precision for Pi such that it matches the perplexity defined by the user\n",
    "    :param Di: vector of length d-1, squared Euclidean distances to all other datapoints (except itself)\n",
    "    :param beta: precision = beta = 1/sigma**2\n",
    "    :return: final probabilites p j|i\n",
    "    \"\"\"\n",
    "    # Compute the Gaussian kernel and entropy for the current precision\n",
    "    logU = np.log(perplexity)\n",
    "    H, thisP = Hbeta(Di, beta)\n",
    "    Hdiff = H - logU\n",
    "\n",
    "    print('Starting binary search')\n",
    "    binarySearch_func = partial(binarySearch, Di=Di, logU=logU)\n",
    "\n",
    "    # Note: the following binary Search for suitable precisions (betas) will be repeated 50 times and does not include the threshold value\n",
    "    (Hdiff, thisP, beta, betamin, betamax), el = scan(binarySearch_func, init=(Hdiff, thisP, beta, betamin, betamax), xs=None, length=1000)    # Set the final row of P\n",
    "    #thisP = np.insert(thisP, iterator, 0)\n",
    "    return beta\n",
    "\n",
    "def x2beta(D: np.ndarray, tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values (high-dim space) in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "    # Initialize some variables\n",
    "    n = D.shape[0]\n",
    "    beta = np.ones(n)      # precisions (1/sigma**2)\n",
    "    betamin = np.full(n, -np.inf)\n",
    "    betamax = np.full(n, np.inf)\n",
    "    betas_final = vmap(partial(x2beta_inner, perplexity=perplexity, tol=tol))(D, np.arange(n), beta=beta, betamin=betamin, betamax=betamax)\n",
    "    return betas_final\n",
    "\n",
    "def x2distance(X):\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    (n, d) = X.shape\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    D = np.reshape(np.delete(D, np.array([i for i in range(0, D.shape[0]**2, (D.shape[0]+1))])), (n , n - 1 ))\n",
    "    return D\n",
    "\n",
    "def distance2p(D, betas):\n",
    "    P_final = vmap(Hbeta_final, in_axes=0)(D, betas)\n",
    "    #print('P_final', P_final, P_final.shape)\n",
    "    P_final = vmap(partial(np.insert, values=0))(P_final, np.arange(P_final.shape[0]))\n",
    "    return P_final\n",
    "\n",
    "def y2q(Y: np.ndarray):\n",
    "    # Compute pairwise affinities\n",
    "    sum_Y = np.sum(np.square(Y), 1)\n",
    "    num = -2. * np.dot(Y, Y.T)  # numerator\n",
    "    num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "    num = num.at[np.diag_indices_from(num)].set(0.)     # numerator\n",
    "    Q = num / np.sum(num)\n",
    "    Q = np.maximum(Q, 1e-12)\n",
    "    return Q, num\n",
    "\n",
    "def KL_divergence(X_flat, Y_flat, X_unflattener, Y_unflattener):\n",
    "    \"\"\"\n",
    "    (R^nxp x R^nxp)--> R\n",
    "    \"\"\"\n",
    "    X = X_unflattener(X_flat)\n",
    "    Y = Y_unflattener(Y_flat)\n",
    "    learning_rate, perplexity = (200, 30.0)\n",
    "    D = x2distance(X)\n",
    "    #print('D', D.shape)\n",
    "    # first compute betas without tracking the derivative\n",
    "    betas = x2beta(jax.lax.stop_gradient(D), tol=1e-5, perplexity=perplexity)\n",
    "    #print('betas', betas.shape, betas)\n",
    "    # use final betas to compute the probability matrix from the distances.\n",
    "    # here D and therefor X is tracked for derivative computation\n",
    "    P = distance2p(D, betas)\n",
    "    P = (P + np.transpose(P))\n",
    "    P = P / np.sum(P)      # Why don't we devide by 2N as described everywhere?\n",
    "    P = np.maximum(P, 1e-12)\n",
    "    #print('P', P, P.shape)\n",
    "    Q, _ = y2q(Y)\n",
    "    print('forward pass done')\n",
    "    #print('Q', Q)\n",
    "    return np.sum(P * (np.log(P+1e-10) - np.log(Q+1e-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "J [[-1.14601536e-03  3.59309022e-04 -4.85297292e-04 ... -1.06886216e-06\n",
      "   1.20807272e-06 -1.98809926e-06]\n",
      " [ 1.53055706e-03  6.50403148e-04 -8.21788795e-04 ... -1.92617995e-06\n",
      "   1.47604638e-07 -7.97213318e-08]\n",
      " [-1.73236299e-06 -3.54500116e-05  2.48225697e-05 ...  2.09047312e-06\n",
      "  -3.22121036e-06  3.82455983e-06]\n",
      " ...\n",
      " [-2.83922600e-06 -7.61937690e-06  1.07138885e-05 ... -3.11852745e-07\n",
      "  -1.63817401e-06 -8.46495254e-07]\n",
      " [-5.08854373e-06  9.43038867e-06  1.20129052e-05 ... -7.50623731e-05\n",
      "  -3.65586675e-06  3.23505665e-05]\n",
      " [-1.11801000e-05 -8.62797515e-06 -6.69115252e-08 ... -2.39926900e-04\n",
      "  -2.02035408e-05 -2.45297619e-04]]\n"
     ]
    }
   ],
   "source": [
    "# fastes version for mixed Jacobian!!!\n",
    "J_X_Y = jacrev(jacfwd(KL_divergence, argnums=1), argnums=0)(X_flat, Y_flat, X_unflattener, Y_unflattener)\n",
    "print('J', J_X_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n"
     ]
    }
   ],
   "source": [
    "f = partial(KL_divergence, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "H = jax.hessian(f, argnums=1)(X_flat, Y_flat)\n",
    "H_pinv = np.linalg.pinv(H + 1e-3*np.eye(len(H)), hermitian=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.1048702e-01 -1.6090722e-01  2.2676721e-01 ...  9.1162761e-04\n",
      "  -1.1729009e-03  2.4877361e-04]\n",
      " [-2.7798456e-01 -1.7961499e-01  2.2067337e-01 ...  4.7490635e-04\n",
      "   2.9332246e-04  3.4087608e-04]\n",
      " [-3.6216539e-03  1.3330627e-02 -7.5492542e-03 ... -1.3888604e-03\n",
      "   1.2332629e-03 -1.1181743e-03]\n",
      " ...\n",
      " [-5.4823514e-02 -4.8064124e-03  8.7097744e-03 ...  5.5088225e-04\n",
      "  -2.1448886e-04 -7.4433578e-05]\n",
      " [-2.5935238e-03 -4.7630360e-03 -1.3998495e-02 ...  9.5764017e-03\n",
      "   1.6811697e-02 -3.3119894e-03]\n",
      " [ 7.5441292e-03  1.4223445e-03  5.7380833e-04 ...  1.2731769e-02\n",
      "   2.2200990e-02  3.9572187e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(-H_pinv, J_X_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jvp_f(f, X_flat, Y_flat):\n",
    "    return jax.jvp(f, (X_flat,), (Y_flat,))[1]\n",
    "\n",
    "def vjp_f(X_flat):\n",
    "    return jax.vjp(f, X_flat)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(0.51993895, dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KL_divergence(X_flat, Y_flat, X_unflattener, Y_unflattener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence_dy(X_flat, Y_flat, X_unflattener, Y_unflattener):\n",
    "    \"\"\"\n",
    "    (R^nxp x R^nxp)--> R\n",
    "    \"\"\"\n",
    "    X = X_unflattener(X_flat)\n",
    "    Y = Y_unflattener(Y_flat)\n",
    "    learning_rate, perplexity = (200, 30.0)\n",
    "    D = x2distance(X)\n",
    "    #print('D', D.shape)\n",
    "    # first compute betas without tracking the derivative\n",
    "    betas = x2beta(jax.lax.stop_gradient(D), tol=1e-5, perplexity=perplexity)\n",
    "    #print('betas', betas.shape, betas)\n",
    "    # use final betas to compute the probability matrix from the distances.\n",
    "    # here D and therefor X is tracked for derivative computation\n",
    "    P = distance2p(D, betas)\n",
    "    P = (P + np.transpose(P))\n",
    "    P = P / np.sum(P)      # Why don't we devide by 2N as described everywhere?\n",
    "    P = np.maximum(P, 1e-12)\n",
    "    #print('P', P, P.shape)\n",
    "    Q, num = y2q(Y)\n",
    "    print('forward pass done')\n",
    "    #print('Q', Q)\n",
    "\n",
    "    PQ = P - Q\n",
    "    PQ_exp = np.expand_dims(PQ, 2)  # NxNx1\n",
    "    Y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)  # nx1x2 - 1xnx2= # NxNx2\n",
    "    num_exp = np.expand_dims(num, 2)    # NxNx1\n",
    "    Y_diffs_wt = Y_diffs * num_exp\n",
    "    return np.ravel(4 * np.sum((PQ_exp * Y_diffs_wt), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n"
     ]
    }
   ],
   "source": [
    "f = partial(KL_divergence_dy, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "J_X_Y = jacrev(f, argnums=0)(X_flat, Y_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n"
     ]
    }
   ],
   "source": [
    "f = partial(KL_divergence_dy, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "H = jax.jacrev(f, argnums=1)(X_flat, Y_flat)\n",
    "H_pinv = np.linalg.pinv(H + 1e-3*np.eye(len(H)), hermitian=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.9759782e-03 -9.9696731e-04 -1.8315598e-06 ...  3.5689940e-04\n",
      "  -1.7652492e-06  6.4417975e-08]\n",
      " [-9.9696754e-04  3.9306288e-03 -1.8981542e-05 ... -6.3432829e-04\n",
      "   7.5418939e-07 -2.0860905e-06]\n",
      " [-1.8315550e-06 -1.8981529e-05  2.6589532e-03 ...  7.8229687e-07\n",
      "   7.7389086e-07 -3.2129719e-06]\n",
      " ...\n",
      " [ 3.5689949e-04 -6.3432805e-04  7.8229840e-07 ...  4.9939742e-03\n",
      "  -5.7279030e-06  8.8372599e-07]\n",
      " [-1.7652492e-06  7.5418211e-07  7.7388677e-07 ... -5.7279121e-06\n",
      "   4.7008181e-03  2.2514626e-04]\n",
      " [ 6.4417520e-08 -2.0860907e-06 -3.2129719e-06 ...  8.8372633e-07\n",
      "   2.2514630e-04  6.5454040e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n"
     ]
    }
   ],
   "source": [
    "f = partial(KL_divergence_dy, Y_flat=Y_flat, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "# jvp\n",
    "_, jvp_fun_lin = jax.linearize(f, X_flat)\n",
    "#jvp_fun = lambda v: jvp(f, (X_flat,), (v,))\n",
    "\n",
    "# vjp\n",
    "_, vjp_fun = vjp(f, X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Array([[ 2.1048674e-01, -1.6090760e-01,  2.2676829e-01, ...,\n",
      "         9.1162801e-04, -1.1729077e-03,  2.4876936e-04],\n",
      "       [-2.7798432e-01, -1.7961535e-01,  2.2067377e-01, ...,\n",
      "         4.7489323e-04,  2.9334135e-04,  3.4088784e-04],\n",
      "       [-3.6215934e-03,  1.3330657e-02, -7.5493040e-03, ...,\n",
      "        -1.3888779e-03,  1.2332662e-03, -1.1181801e-03],\n",
      "       ...,\n",
      "       [-5.4823834e-02, -4.8064608e-03,  8.7097837e-03, ...,\n",
      "         5.5088318e-04, -2.1448985e-04, -7.4437441e-05],\n",
      "       [-2.5935331e-03, -4.7630374e-03, -1.3998534e-02, ...,\n",
      "         9.5764417e-03,  1.6811693e-02, -3.3120278e-03],\n",
      "       [ 7.5442195e-03,  1.4223302e-03,  5.7384721e-04, ...,\n",
      "         1.2731675e-02,  2.2200927e-02,  3.9572086e-02]], dtype=float32),)\n",
      "time:  0.37227821350097656\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#time_start = time.time()\n",
    "#print(vmap(jvp_fun_lin)(np.eye(len(X_flat))))\n",
    "#time_end = time.time()\n",
    "#print('time', time_end - time_start)\n",
    "\n",
    "#time_start = time.time()\n",
    "#print(vmap(jvp_fun)(np.eye(len(X_flat))))\n",
    "#time_end = time.time()\n",
    "#print('time', time_end - time_start)\n",
    "\n",
    "# best version!!!!\n",
    "time_start = time.time()\n",
    "print(vmap(vjp_fun)(-H_pinv))\n",
    "time_end = time.time()\n",
    "print('time: ', time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cov(vjp_fun, jvp_fun_lin, H_pinv_i, D, N, d, n):\n",
    "  v1 = vjp_fun(-H_pinv_i)[0]\n",
    "  print(v1)\n",
    "  v2 = np.ravel(np.dot(np.dot(N, np.reshape(v1, (n, d), 'C')),np.transpose(D)), 'C')\n",
    "  v3 = jvp_fun_lin(v2)\n",
    "  return v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "Traced<ShapedArray(float32[6350])>with<BatchTrace(level=1/0)> with\n",
      "  val = Array([[ 1.2624934e-01,  3.0275151e-01,  5.3603001e-02, ...,\n",
      "         1.4042221e-04,  2.4873446e-04,  4.6364780e-04],\n",
      "       [ 3.7767626e-02, -1.0878614e-01, -7.5483881e-02, ...,\n",
      "        -1.5412066e-04, -2.1876383e-04, -2.6198086e-05],\n",
      "       [ 8.1862500e-03, -8.4853005e-03,  3.2339965e-03, ...,\n",
      "        -1.5797181e-05,  4.9772236e-04,  4.1241435e-04],\n",
      "       ...,\n",
      "       [ 7.1977056e-04,  5.2695966e-04, -1.2600278e-04, ...,\n",
      "        -3.3954016e-03,  4.3024647e-04,  3.5436866e-03],\n",
      "       [ 4.6736770e-04, -1.8354435e-04, -8.2751544e-04, ...,\n",
      "        -4.0454887e-02,  8.8763125e-03,  1.4777500e-02],\n",
      "       [ 1.8533238e-03,  1.1596166e-03, -1.2639432e-03, ...,\n",
      "        -5.4364543e-02, -1.8488355e-03,  8.1184745e-02]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "time:  0.49882006645202637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_spd_matrix\n",
    "D = make_spd_matrix(X.shape[1])\n",
    "N = make_spd_matrix(X.shape[0])\n",
    "\n",
    "f = partial(KL_divergence_dy, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "H = jax.jacrev(f, argnums=1)(X_flat, Y_flat)\n",
    "H_pinv = np.linalg.pinv(H + 1e-3*np.eye(len(H)), hermitian=True)\n",
    "\n",
    "f = partial(KL_divergence_dy, Y_flat=Y_flat, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "# jvp\n",
    "_, jvp_fun_lin = jax.linearize(f, X_flat)\n",
    "# vjp\n",
    "_, vjp_fun = vjp(f, X_flat)\n",
    "\n",
    "time_start = time.time()\n",
    "compute_cov_fun = lambda i: compute_cov(vjp_fun=vjp_fun, jvp_fun_lin=jvp_fun_lin, \n",
    "                                        H_pinv_i=i, D=D, N=N, d=D.shape[0], n=N.shape[0])\n",
    "vmap(compute_cov_fun)(H_pinv)\n",
    "time_end = time.time()\n",
    "print('time: ', time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "Computing pairwise distances...\n",
      "Starting binary search\n",
      "Entered binary search function\n",
      "forward pass done\n",
      "[[ 1.26248375e-01  3.02749753e-01  5.36025316e-02 ...  1.40419856e-04\n",
      "   2.48732948e-04  4.63638135e-04]\n",
      " [ 3.77679951e-02 -1.08785085e-01 -7.54834563e-02 ... -1.54116351e-04\n",
      "  -2.18762434e-04 -2.62033518e-05]\n",
      " [ 8.18620156e-03 -8.48526414e-03  3.23403650e-03 ... -1.57897048e-05\n",
      "   4.97719739e-04  4.12389403e-04]\n",
      " ...\n",
      " [ 7.19800766e-04  5.26952499e-04 -1.26017112e-04 ... -3.39537626e-03\n",
      "   4.30253975e-04  3.54363560e-03]\n",
      " [ 4.67383681e-04 -1.83537079e-04 -8.27537209e-04 ... -4.04547267e-02\n",
      "   8.87632929e-03  1.47777274e-02]\n",
      " [ 1.85331574e-03  1.15959859e-03 -1.26393628e-03 ... -5.43645546e-02\n",
      "  -1.84881256e-03  8.11846927e-02]]\n"
     ]
    }
   ],
   "source": [
    "def compute_dy_dx(f, X, Y):\n",
    "  H = jax.hessian(f, argnums=1)(X_flat, Y_flat)\n",
    "  H_pinv = np.linalg.pinv(H + 1e-3*np.eye(len(H)), hermitian=True)\n",
    "  J_X_Y = jacrev(jacfwd(f, argnums=1), argnums=0)(X_flat, Y_flat)\n",
    "  return np.dot(-H_pinv, J_X_Y)\n",
    "\n",
    "f = partial(KL_divergence, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "dy_dx = compute_dy_dx(f, X_flat, Y_flat)\n",
    "print(dy_dx)\n",
    "#np.dot(np.dot(dy_dx, np.kron(D, N)), dy_dx.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
