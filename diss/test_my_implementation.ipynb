{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "from functools import partial\n",
    "from jax import vmap\n",
    "from jax.lax import scan\n",
    "from jax.lax import cond\n",
    "from jax import random\n",
    "from jax import jit\n",
    "from jax import jacrev\n",
    "from jax.lax import stop_gradient\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import manifold, datasets\n",
    "import seaborn as sns\n",
    "import jax\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "import jax.numpy as np\n",
    "from utils import MidpointNormalize, load_data\n",
    "from jax import random, flatten_util, vjp, jvp, custom_vjp, jacfwd, jacrev, vmap, grad\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from tsne_jax import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Finding 49 nearest neighbors using Annoy approximate search using euclidean distance...\n",
      "   --> Time elapsed: 0.01 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.00 seconds\n",
      "===> Running optimization with exaggeration=12.00, lr=200.00 for 250 iterations...\n",
      "Iteration   50, KL divergence 0.8921, 50 iterations in 0.2886 sec\n",
      "Iteration  100, KL divergence 0.9531, 50 iterations in 0.2763 sec\n",
      "Iteration  150, KL divergence 0.9984, 50 iterations in 0.2764 sec\n",
      "Iteration  200, KL divergence 0.8934, 50 iterations in 0.2850 sec\n",
      "Iteration  250, KL divergence 0.9448, 50 iterations in 0.2809 sec\n",
      "   --> Time elapsed: 1.41 seconds\n",
      "===> Running optimization with exaggeration=1.00, lr=200.00 for 750 iterations...\n",
      "Iteration   50, KL divergence 0.0109, 50 iterations in 0.3351 sec\n",
      "Iteration  100, KL divergence 0.0109, 50 iterations in 0.3248 sec\n",
      "Iteration  150, KL divergence 0.0109, 50 iterations in 0.3070 sec\n",
      "Iteration  200, KL divergence 0.0109, 50 iterations in 0.3073 sec\n",
      "Iteration  250, KL divergence 0.0109, 50 iterations in 0.3205 sec\n",
      "Iteration  300, KL divergence 0.0109, 50 iterations in 0.3191 sec\n",
      "Iteration  350, KL divergence 0.0109, 50 iterations in 0.2686 sec\n",
      "Iteration  400, KL divergence 0.0109, 50 iterations in 0.4120 sec\n",
      "Iteration  450, KL divergence 0.0109, 50 iterations in 0.2638 sec\n",
      "Iteration  500, KL divergence 0.0109, 50 iterations in 0.2662 sec\n",
      "Iteration  550, KL divergence 0.0109, 50 iterations in 0.2638 sec\n",
      "Iteration  600, KL divergence 0.0109, 50 iterations in 0.2619 sec\n",
      "Iteration  650, KL divergence 0.0109, 50 iterations in 0.2664 sec\n",
      "Iteration  700, KL divergence 0.0109, 50 iterations in 0.2657 sec\n",
      "Iteration  750, KL divergence 0.0109, 50 iterations in 0.2625 sec\n",
      "   --> Time elapsed: 4.45 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs, make_classification\n",
    "#X, y = load_data(40)\n",
    "X, y = make_blobs(n_samples=50, n_features=1000, centers=4, random_state=0, shuffle=False, cluster_std=[0.1, 3, 3, 3])\n",
    "#X, y = make_classification(n_classes=5, n_samples=50, n_features=1000, random_state=42)\n",
    "key = random.PRNGKey(41)\n",
    "#X = onp.array(random.normal(key, shape=(50, 50)))\n",
    "y_guess = random.normal(key, shape=(X.shape[0], 2))\n",
    "#Y_star = TSNE(n_components=2, learning_rate=200, init=onp.array(y_guess), perplexity=30).fit_transform(X)\n",
    "Y_star = tsne_fwd(X, y_guess)\n",
    "\n",
    "X_flat, X_unflattener = flatten_util.ravel_pytree(X)   # row-wise\n",
    "Y_flat, Y_unflattener = flatten_util.ravel_pytree(Y_star) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1.9144871234893799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_spd_matrix\n",
    "D = make_spd_matrix(X.shape[1])\n",
    "N = make_spd_matrix(X.shape[0])\n",
    "\n",
    "f = partial(KL_divergence_dy, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "H = jax.jacrev(f, argnums=1)(X_flat, Y_flat)\n",
    "H_pinv = np.linalg.pinv(H + 1e-3*np.eye(len(H)), hermitian=True)\n",
    "\n",
    "f = partial(KL_divergence_dy, Y_flat=Y_flat, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "# jvp\n",
    "_, jvp_fun_lin = jax.linearize(f, X_flat)\n",
    "# vjp\n",
    "_, vjp_fun = vjp(f, X_flat)\n",
    "\n",
    "time_start = time.time()\n",
    "compute_cov_fun = lambda i: compute_cov_inner(vjp_fun=vjp_fun, jvp_fun_lin=jvp_fun_lin, \n",
    "                                        H_pinv_i=i, D=D, N=N, d=D.shape[0], n=N.shape[0], H_pinv=H_pinv)\n",
    "final_cov = vmap(compute_cov_fun)(H_pinv)\n",
    "time_end = time.time()\n",
    "print('time: ', time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final covariance [[ 6.22437801e-04  4.94177686e-04 -7.45397876e-04 ...  3.73561234e-05\n",
      "   1.62843266e-04  1.53749439e-04]\n",
      " [ 4.94178385e-04  8.50181037e-04  7.12622132e-05 ... -3.85209860e-05\n",
      "  -5.34712162e-05 -8.52075245e-05]\n",
      " [-7.45398167e-04  7.12624824e-05  5.09006064e-03 ... -3.36255820e-04\n",
      "  -1.00966287e-03 -1.06366130e-03]\n",
      " ...\n",
      " [ 3.73560215e-05 -3.85210587e-05 -3.36255529e-04 ...  2.10113125e-04\n",
      "   7.44308418e-05  1.09948145e-04]\n",
      " [ 1.62843324e-04 -5.34712672e-05 -1.00966287e-03 ...  7.44307981e-05\n",
      "   3.46692163e-04  3.32814030e-04]\n",
      " [ 1.53749468e-04 -8.52074591e-05 -1.06366142e-03 ...  1.09948174e-04\n",
      "   3.32814117e-04  4.45897196e-04]]\n"
     ]
    }
   ],
   "source": [
    "#print('KL divergence: ', KL_divergence(X_flat, Y_flat, X_unflattener, Y_unflattener))\n",
    "#print('derivative of KL divergence w.r.t. Y: ', KL_divergence_dy(X_flat, Y_flat, X_unflattener, Y_unflattener))\n",
    "#print('Hessian', H)\n",
    "print('final covariance', final_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dy_dx(f, X, Y):\n",
    "  H = jax.hessian(f, argnums=1)(X_flat, Y_flat)\n",
    "  #print('Hessian: ', H)\n",
    "  H_pinv = np.linalg.pinv(H + 1e-3*np.eye(len(H)), hermitian=True)\n",
    "  J_X_Y = jacrev(jacfwd(f, argnums=1), argnums=0)(X_flat, Y_flat)\n",
    "  return np.dot(-H_pinv, J_X_Y)\n",
    "\n",
    "f = partial(KL_divergence, X_unflattener=X_unflattener, Y_unflattener=Y_unflattener)\n",
    "dy_dx = compute_dy_dx(f, X_flat, Y_flat)\n",
    "final = np.dot(np.dot(dy_dx, np.kron(D, N)), dy_dx.T)\n",
    "print('final cov: ', final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
