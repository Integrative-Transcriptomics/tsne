{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9778a107-b0eb-41d3-9246-d850ef88a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import sys, os\n",
    "from os import path\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as np\n",
    "from jax import vjp, custom_vjp\n",
    "from functools import partial\n",
    "import openTSNE\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "712bf08f-0e83-4d97-8307-1bef54518250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(n_samples=None):\n",
    "    with gzip.open(path.join(\"examples/data/mnist\", \"mnist.pkl.gz\"), \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    x, y = data[\"pca_50\"], data[\"labels\"]\n",
    "\n",
    "    if n_samples is not None:\n",
    "        indices = onp.random.choice(\n",
    "            list(range(x.shape[0])), n_samples, replace=False\n",
    "        )\n",
    "        x, y = x[indices], y[indices]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a01e33b8-a1e5-4865-9bf6-3953f068cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(custom_vjp, nondiff_argnums=(0,))\n",
    "def fixed_point(f, x, y_guess):\n",
    "    affinity = openTSNE.affinity.PerplexityBasedNN(\n",
    "        x,\n",
    "        perplexity=30.0,\n",
    "        method=\"annoy\",\n",
    "        random_state=42,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    init = openTSNE.initialization.random(\n",
    "        x, n_components=2, random_state=42, verbose=True,\n",
    "    )\n",
    "    \n",
    "    y_star = openTSNE.TSNEEmbedding(\n",
    "        init,\n",
    "        affinity,\n",
    "        learning_rate=200,\n",
    "        negative_gradient_method=\"fft\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    y_star.optimize(250, exaggeration=12, momentum=0.8, inplace=True)\n",
    "    y_star.optimize(750, momentum=0.5, inplace=True)\n",
    "    return y_star\n",
    "\n",
    "def fixed_point_fwd(f, x, y_guess):\n",
    "    y_star = fixed_point(f, x, y_guess)\n",
    "    return y_star, (x, y_star)\n",
    "\n",
    "def fixed_point_bwd(f, res, y_star_bar):\n",
    "    x, y_star = res\n",
    "    _, vjp_x = vjp(lambda x: f(x, y_star), x)\n",
    "    x_bar, = vjp_x(1.)\n",
    "    return x_bar, jnp.zeros_like(y_star)\n",
    "fixed_point.defvjp(fixed_point_fwd, fixed_point_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e0954-d54e-450d-a300-cac67fe33e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(x, y):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5091e739-48e3-4a8e-92c0-716ee6c534b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, label = load_data(n_samples=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00f76f70-8632-429d-a26b-0ef0d55bdb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Finding 90 nearest neighbors using Annoy approximate search using euclidean distance...\n",
      "   --> Time elapsed: 0.12 seconds\n",
      "===> Calculating affinity matrix...\n",
      "   --> Time elapsed: 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(42)\n",
    "y_guess = random.normal(key, shape=(x.shape[0], 2))\n",
    "#y_star = fixed_point(lambda r, t: (r-2)*t, x, y_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a5f3390-dfd8-48ee-9ffa-9351c326ff55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSNEEmbedding([[ 9.69815460e+00,  5.79930041e+00],\n",
       "               [-1.05424794e+01,  3.76391981e+00],\n",
       "               [ 9.58967456e+00, -7.17843019e+00],\n",
       "               [-1.67044756e+01, -9.49710197e+00],\n",
       "               [-1.82768855e+01,  7.70417316e+00],\n",
       "               [-5.04795673e+00, -1.73491630e+01],\n",
       "               [-9.72283509e+00, -1.75503996e+01],\n",
       "               [ 7.58853717e+00, -6.25629911e+00],\n",
       "               [ 6.94522796e+00,  1.81062866e+01],\n",
       "               [ 9.13919778e+00, -2.13848410e+00],\n",
       "               [ 1.56999103e+00,  5.69943422e+00],\n",
       "               [ 3.83729918e-01,  2.01975948e+01],\n",
       "               [ 4.93949640e-01,  8.66656955e+00],\n",
       "               [ 1.19741488e+01,  4.64422484e+00],\n",
       "               [ 3.72802212e+00, -1.51540405e+01],\n",
       "               [ 9.01455380e+00,  4.20599988e+00],\n",
       "               [-7.23465139e+00, -1.65239464e+01],\n",
       "               [ 6.39212972e+00, -1.24174902e+01],\n",
       "               [-9.95663713e+00,  4.24574968e+00],\n",
       "               [ 1.44630866e+01, -1.36119630e+01],\n",
       "               [-6.25261079e+00,  1.91735229e+01],\n",
       "               [-1.63595753e+01, -3.95246434e+00],\n",
       "               [ 7.49883136e-01, -3.85836434e+00],\n",
       "               [-5.14603989e+00, -1.60980163e+00],\n",
       "               [ 1.45842643e+01, -9.53041552e+00],\n",
       "               [ 2.63646708e+00, -2.47223565e+00],\n",
       "               [-4.34125418e+00,  2.07395783e+01],\n",
       "               [-2.16373183e+01,  5.59610891e+00],\n",
       "               [ 8.04829003e+00, -1.39759899e+01],\n",
       "               [-1.28029587e+01, -7.54551939e-01],\n",
       "               [ 1.60494434e+01, -2.24654174e+00],\n",
       "               [-1.10775693e+01, -7.36970410e+00],\n",
       "               [-8.11061292e+00,  1.85614394e+01],\n",
       "               [-2.08158199e+01,  3.87444771e+00],\n",
       "               [-1.79597248e+01,  8.57179977e+00],\n",
       "               [ 6.01195056e-01, -5.51069287e+00],\n",
       "               [ 3.48230434e+00, -1.75859493e-02],\n",
       "               [-6.91260000e+00,  1.34608555e+01],\n",
       "               [ 6.52251084e+00,  1.34053509e+01],\n",
       "               [-7.19493807e+00, -1.54167094e+01],\n",
       "               [-1.75055253e+01, -1.07085367e+01],\n",
       "               [-1.07739800e+01,  9.63284939e+00],\n",
       "               [-6.43638997e+00, -1.65996396e+01],\n",
       "               [ 1.52575382e+01, -9.49908963e+00],\n",
       "               [-4.68034158e+00,  1.75546518e+01],\n",
       "               [ 4.34169763e+00,  1.97703167e+01],\n",
       "               [-1.94806445e+01,  5.91538529e+00],\n",
       "               [-6.19458194e+00, -1.41416556e+01],\n",
       "               [-2.01550163e+01,  6.53905172e+00],\n",
       "               [ 2.75157628e+00, -1.23841262e+01],\n",
       "               [ 8.59487401e+00,  3.89968174e+00],\n",
       "               [ 1.10531172e+01,  2.11960623e+00],\n",
       "               [ 8.99252130e+00, -8.47648948e+00],\n",
       "               [ 5.56845469e+00,  8.63475814e+00],\n",
       "               [ 2.14687967e-01, -1.58631943e+01],\n",
       "               [-2.17671309e+00,  1.38845192e+01],\n",
       "               [ 2.15372086e+01, -9.81527291e+00],\n",
       "               [ 1.33889722e+01,  4.83038924e+00],\n",
       "               [ 3.24152430e+00, -1.15699360e+01],\n",
       "               [-1.76081843e+00,  3.00378297e+00],\n",
       "               [-7.06161557e+00, -6.84726288e+00],\n",
       "               [ 2.44158533e-01,  2.92557543e+00],\n",
       "               [-2.29818962e+01,  8.85569419e+00],\n",
       "               [-9.12724212e+00, -2.56719053e+00],\n",
       "               [ 1.44081715e+00,  1.90380398e+01],\n",
       "               [ 2.74024276e+00,  9.34089825e+00],\n",
       "               [-1.98495771e+00, -8.19336536e+00],\n",
       "               [-8.11660438e+00, -2.53545571e+00],\n",
       "               [-2.05259639e+01,  7.77558683e+00],\n",
       "               [-2.68491404e+00,  8.26506671e+00],\n",
       "               [ 1.68108590e+01, -1.21331447e+01],\n",
       "               [-1.85569573e+01,  7.80678160e+00],\n",
       "               [-5.46698672e+00, -1.31657735e+01],\n",
       "               [ 4.82764730e+00, -4.39331328e+00],\n",
       "               [-2.42121446e+01,  3.41199103e+00],\n",
       "               [ 6.40313799e-01,  1.61074526e+01],\n",
       "               [-8.68586186e+00, -1.83731316e+00],\n",
       "               [ 1.02530650e+00,  1.57719121e+01],\n",
       "               [-1.25880061e-01, -7.37742562e+00],\n",
       "               [-4.30898519e+00,  1.48879837e+01],\n",
       "               [ 9.52773103e+00,  2.87117884e+00],\n",
       "               [-9.92628938e+00, -4.86545696e+00],\n",
       "               [ 5.69915743e+00,  1.89586867e+01],\n",
       "               [-8.05764524e-01, -1.43155350e+01],\n",
       "               [ 1.80987876e+01, -9.81330509e+00],\n",
       "               [ 1.06164615e+01, -1.11922668e+01],\n",
       "               [ 8.09183572e+00, -4.59446412e+00],\n",
       "               [ 4.53652796e+00, -4.97729838e+00],\n",
       "               [ 8.50619194e+00,  9.03413049e+00],\n",
       "               [-7.17852546e+00, -1.01976686e+00],\n",
       "               [-1.93510439e+01,  1.06794090e+01],\n",
       "               [ 1.36091004e+01, -1.53993163e+01],\n",
       "               [ 8.01479387e+00,  7.92810738e+00],\n",
       "               [-6.71323079e+00,  1.81591907e+01],\n",
       "               [-2.74973201e+00,  7.01425255e+00],\n",
       "               [ 1.44532485e+00, -1.14474104e+01],\n",
       "               [ 7.21804267e-01, -1.47650944e+01],\n",
       "               [ 1.03808433e+01, -4.85714651e+00],\n",
       "               [ 8.91583296e+00, -1.03581889e+01],\n",
       "               [-9.71610379e+00,  6.06778033e+00],\n",
       "               [ 1.71807362e+01, -4.46490391e+00],\n",
       "               [-7.08349984e+00, -1.84989078e+01],\n",
       "               [-1.29956469e+01, -7.85167671e+00],\n",
       "               [-1.67125126e+01, -1.05410462e+01],\n",
       "               [-2.20442437e+01,  4.16910176e+00],\n",
       "               [ 1.05515187e+01, -1.10542975e+01],\n",
       "               [-8.75128009e+00, -2.87184503e+00],\n",
       "               [-2.73662666e+00,  3.41432062e+00],\n",
       "               [-4.50129930e-01,  1.77378810e+01],\n",
       "               [-4.04219869e+00, -2.43910300e-01],\n",
       "               [ 1.43712915e+01, -1.61478910e+01],\n",
       "               [-8.11019326e+00,  2.74628376e-01],\n",
       "               [-2.32250595e+01,  8.14552534e+00],\n",
       "               [-4.11826879e-01, -4.19848111e+00],\n",
       "               [-6.64081203e+00,  1.87273684e+01],\n",
       "               [-3.82495768e-01, -1.41522978e-01],\n",
       "               [-1.54354184e+01, -1.22697824e+01],\n",
       "               [ 9.20701885e+00,  5.47720733e+00],\n",
       "               [ 1.59181634e+00,  7.67787009e-01],\n",
       "               [-9.86219282e+00, -6.71589917e+00],\n",
       "               [-2.18205686e+00, -6.97597747e+00],\n",
       "               [ 2.14683948e+01, -6.07267184e+00],\n",
       "               [-2.00428441e+00, -8.63822708e+00],\n",
       "               [-1.10479884e+01, -8.78143501e+00],\n",
       "               [ 5.50048873e+00, -1.30499992e+01],\n",
       "               [ 2.17260517e+00,  7.32640974e+00],\n",
       "               [ 1.46575422e+01, -1.26453213e+01],\n",
       "               [ 1.93083293e+00, -1.09842680e+01],\n",
       "               [ 2.15037141e+01, -9.08625777e+00],\n",
       "               [ 3.54522976e+00,  1.65001131e+01],\n",
       "               [-7.02730622e+00,  1.09155692e+01],\n",
       "               [ 4.76152049e+00,  1.71777398e+01],\n",
       "               [ 8.19426601e+00, -2.03741931e+00],\n",
       "               [ 1.82555312e+01, -1.37717706e+01],\n",
       "               [-9.40453959e+00, -2.12809645e+00],\n",
       "               [ 1.63466099e+01, -9.71035686e+00],\n",
       "               [-5.70877198e+00,  1.67676306e+01],\n",
       "               [ 1.50303750e+01, -1.05709785e+01],\n",
       "               [-2.16917741e+01,  4.37032936e+00],\n",
       "               [ 9.67345737e+00, -8.28588901e+00],\n",
       "               [-2.09289244e+01,  1.06018232e+01],\n",
       "               [ 3.71857976e+00,  1.57504424e+01],\n",
       "               [-6.27465700e+00, -8.13938112e+00],\n",
       "               [ 5.63684709e+00, -1.56380318e+01],\n",
       "               [-7.17783945e+00, -3.98790400e-01],\n",
       "               [-5.75472874e+00,  1.77075643e+01],\n",
       "               [-3.19400461e+00,  1.17268761e+01],\n",
       "               [ 6.77961159e+00,  1.42163982e+01],\n",
       "               [ 2.11109653e-01,  8.22493885e+00],\n",
       "               [-2.27392548e+00, -6.99194728e+00],\n",
       "               [ 1.14497189e+01, -5.15758998e+00],\n",
       "               [-5.97822835e+00, -1.36291641e+01],\n",
       "               [ 1.72785710e+01, -1.89693757e+00],\n",
       "               [-2.14549915e+00,  1.83961691e+01],\n",
       "               [-5.77909074e+00,  2.09356105e+01],\n",
       "               [-2.17799968e+01,  8.41044130e+00],\n",
       "               [-2.01694130e+01,  1.03092371e+01],\n",
       "               [ 1.81879700e+00,  1.91940052e+01],\n",
       "               [ 1.27595932e+01, -1.12120863e+01],\n",
       "               [ 4.02006623e+00,  3.92919992e+00],\n",
       "               [ 7.09300111e+00, -1.45793032e+01],\n",
       "               [ 1.27150303e+00,  1.26268215e+00],\n",
       "               [-1.24391662e+00,  1.00416336e+01],\n",
       "               [-5.29138457e+00, -5.17837355e+00],\n",
       "               [-4.35358535e+00,  1.50513696e+00],\n",
       "               [ 1.05044324e+01, -4.81763290e+00],\n",
       "               [ 1.73980251e+01, -1.07892661e+01],\n",
       "               [-7.30504340e+00, -5.60977281e+00],\n",
       "               [-1.61749251e+01, -1.21031458e+01],\n",
       "               [-1.09446171e+01, -7.82510689e+00],\n",
       "               [-1.06132500e-02, -1.11162013e+01],\n",
       "               [ 3.06786411e+00,  1.90781404e+01],\n",
       "               [ 6.27111071e+00, -1.39951373e+01],\n",
       "               [-4.28603887e-02,  1.21041473e+01],\n",
       "               [-1.57454977e+01, -9.96876990e+00],\n",
       "               [-1.19147165e+00, -1.23827990e+01],\n",
       "               [ 2.02279142e+00,  1.21154583e+01],\n",
       "               [-9.93705238e+00, -1.76245912e+01],\n",
       "               [ 1.55959075e+01, -2.49252976e-02],\n",
       "               [ 2.50880918e-01, -7.19615321e+00],\n",
       "               [-3.09399000e+00, -2.02914741e+00],\n",
       "               [-2.35655251e+01,  6.53959706e+00],\n",
       "               [-2.05532049e+01, -1.02788657e+01],\n",
       "               [ 1.33382794e+00,  1.55287020e+00],\n",
       "               [ 1.78971672e+01, -1.52348774e+01],\n",
       "               [ 7.84930726e+00, -1.40030887e+01],\n",
       "               [ 4.70780939e+00,  4.53373010e+00],\n",
       "               [-1.85581420e+01, -8.14409416e+00],\n",
       "               [-8.02196893e+00,  7.31718398e+00],\n",
       "               [ 3.86373655e-01,  7.28881568e+00],\n",
       "               [ 4.81451494e+00, -9.68628697e+00],\n",
       "               [-2.13202076e+01, -1.00136420e+01],\n",
       "               [-5.95859043e+00, -2.47530387e+00],\n",
       "               [-1.64810382e+01, -4.46953658e+00],\n",
       "               [-3.31508845e-01,  1.92692933e+01],\n",
       "               [ 1.35203808e+01, -1.34900315e+01],\n",
       "               [-2.04004878e+01, -1.03788806e+01],\n",
       "               [ 6.26094521e+00, -1.09126753e+00],\n",
       "               [-7.30867248e+00, -1.37906408e+01],\n",
       "               [-8.90155536e+00, -1.17097169e+00],\n",
       "               [-1.43192176e+01,  1.78514086e+00],\n",
       "               [ 2.32774763e-01, -1.51704900e+00],\n",
       "               [-1.45324482e+01, -5.85619670e+00],\n",
       "               [ 4.97969401e+00, -7.15764161e+00],\n",
       "               [ 1.40127949e+01, -7.16833783e+00],\n",
       "               [-2.16661746e+01,  6.65338784e+00],\n",
       "               [-2.14750694e+01,  1.03483143e+01],\n",
       "               [ 6.42807153e+00, -2.93211917e+00],\n",
       "               [-6.12771593e-02,  7.71058274e-01],\n",
       "               [ 1.46863328e+01, -7.22427942e+00],\n",
       "               [-6.16287437e-01, -1.54768404e+01],\n",
       "               [ 2.79647513e+00,  1.78832309e+01],\n",
       "               [-2.36837456e+01,  8.23748058e+00],\n",
       "               [ 2.68378105e+00,  1.29636426e+01],\n",
       "               [-2.39705751e+01,  3.50793308e+00],\n",
       "               [-2.37916962e+01,  5.65246800e+00],\n",
       "               [ 1.21997627e+01,  6.42857143e+00],\n",
       "               [ 5.25022831e+00,  1.39398726e+01],\n",
       "               [-5.28563644e+00,  1.02288369e+01],\n",
       "               [ 8.31819165e-01,  1.24778643e+01],\n",
       "               [-2.95871763e+00,  9.02157894e+00],\n",
       "               [ 3.30934281e+00, -1.19251190e+01],\n",
       "               [-4.09884243e+00, -1.82479813e+01],\n",
       "               [-8.63982736e-01, -8.62693550e-01],\n",
       "               [ 4.03289301e+00,  2.61904960e+00],\n",
       "               [ 1.35856303e+01, -4.00555783e+00],\n",
       "               [ 6.69060558e+00,  1.45136054e+00],\n",
       "               [ 8.85925444e-01, -4.01213590e+00],\n",
       "               [-2.20024042e+00,  2.15071742e+01],\n",
       "               [ 7.74871157e+00, -5.83826703e+00],\n",
       "               [-6.11625468e+00, -2.15230220e+00],\n",
       "               [-2.00314955e+00,  1.82567186e+01],\n",
       "               [ 6.61464272e+00,  6.17332676e+00],\n",
       "               [ 1.56084845e+01, -1.74349238e+01],\n",
       "               [ 1.04059622e+01,  4.85380572e+00],\n",
       "               [-6.07494746e+00,  6.38461128e-01],\n",
       "               [ 6.93454719e+00,  2.81879635e+00],\n",
       "               [ 1.77056656e+01, -1.46806409e+01],\n",
       "               [-1.51887167e+01, -5.52833083e+00],\n",
       "               [ 1.32947624e+01, -1.74662296e+00],\n",
       "               [-1.15425680e+01,  1.09877393e+01],\n",
       "               [-1.66661731e+01, -1.12215084e+01],\n",
       "               [ 6.63485907e+00, -2.15999393e+00],\n",
       "               [ 1.52839841e+01, -1.42505781e+01],\n",
       "               [ 1.10754349e+01,  5.93253604e+00],\n",
       "               [-5.23096540e+00,  6.07787941e+00],\n",
       "               [ 1.50038210e+01, -1.65930085e+01],\n",
       "               [ 5.94835830e+00,  1.65872082e+01],\n",
       "               [ 1.34864135e+00, -1.11079770e+01],\n",
       "               [ 2.16316851e+01, -9.46952528e+00],\n",
       "               [ 3.28542658e+00,  6.88204551e+00],\n",
       "               [ 1.49828390e+01, -1.21357327e+01],\n",
       "               [ 1.17337178e-01,  1.92222428e+01],\n",
       "               [ 1.18916304e+01,  7.09766248e+00],\n",
       "               [-7.00693925e-01, -1.63877963e+01],\n",
       "               [ 6.39497493e+00, -5.50176232e-01],\n",
       "               [ 1.03025570e+01,  2.78732446e+00],\n",
       "               [-5.62340839e+00, -9.16674337e-01],\n",
       "               [-1.59342625e+00, -7.35077521e-02],\n",
       "               [-1.33860917e+01, -4.58517189e+00],\n",
       "               [-1.17818049e+01, -7.33920681e+00],\n",
       "               [ 6.62526770e+00,  1.77927098e+01],\n",
       "               [ 4.88147290e+00,  1.77909061e+01],\n",
       "               [ 4.90947808e+00,  1.33002329e+01],\n",
       "               [-2.05687596e+01,  9.07013530e+00],\n",
       "               [-1.81118342e+01,  6.73701002e+00],\n",
       "               [-4.75786265e+00, -1.39729975e+01],\n",
       "               [ 5.17361281e+00, -4.11240123e+00],\n",
       "               [ 3.39998235e+00,  1.43443691e+01],\n",
       "               [ 5.30474762e+00,  1.98615803e+01],\n",
       "               [ 3.91336492e+00, -1.61652326e+00],\n",
       "               [-1.97494431e+00,  1.10094264e+01],\n",
       "               [ 1.30336712e+01, -9.56493115e+00],\n",
       "               [ 1.03067451e+00, -6.96542886e+00],\n",
       "               [-3.57998421e+00,  1.78328794e+01],\n",
       "               [ 1.11324763e+01,  3.71598572e+00],\n",
       "               [-4.45790993e-01,  1.27016348e+01],\n",
       "               [-8.96749657e+00,  7.23658481e+00],\n",
       "               [ 1.57917102e+01, -1.36177664e+01],\n",
       "               [ 2.59130722e+00,  9.14157097e+00],\n",
       "               [ 1.86196194e+01, -7.15908569e+00],\n",
       "               [-2.23909216e-01,  8.96590381e+00],\n",
       "               [-3.90065439e+00,  2.06530144e+01],\n",
       "               [ 1.51472698e+00,  6.23124915e-02],\n",
       "               [-1.77631117e+01, -1.01859460e+01],\n",
       "               [ 5.82039522e+00,  1.48172751e+01],\n",
       "               [-2.31238455e+01,  5.10720887e+00],\n",
       "               [ 1.28484209e+00,  1.17577098e+01],\n",
       "               [ 1.65304815e+01, -1.05753353e+01],\n",
       "               [-1.05657195e+01,  9.29107782e+00],\n",
       "               [ 1.36382521e+01,  3.05864202e+00],\n",
       "               [-4.55570535e+00,  3.98763842e-01],\n",
       "               [-2.82918030e+00,  2.09411535e+01],\n",
       "               [ 1.32582129e+01, -1.09604964e+01],\n",
       "               [-5.38585585e+00,  1.70072950e+01],\n",
       "               [ 2.52123641e+00, -8.96832052e+00],\n",
       "               [-2.27508579e+01,  5.37229938e+00],\n",
       "               [ 1.83418971e+01, -3.36668475e+00],\n",
       "               [ 4.70750558e-01,  1.48391151e+01],\n",
       "               [ 1.84871619e+01, -2.89671137e+00],\n",
       "               [ 8.70240880e+00,  7.22406722e+00],\n",
       "               [ 1.12542376e+01,  4.69033281e+00],\n",
       "               [-6.07071005e-01, -5.11586584e+00],\n",
       "               [ 5.14765094e-01, -1.37915323e+01],\n",
       "               [ 3.04615119e+00,  5.80270557e+00],\n",
       "               [ 1.13956801e+01,  1.52297633e+01],\n",
       "               [ 4.31148604e+00,  1.89196292e+01],\n",
       "               [ 9.30715810e+00,  2.33253559e+00],\n",
       "               [-6.31216987e+00, -7.81621155e+00],\n",
       "               [-6.80087962e+00, -2.59254920e+00],\n",
       "               [ 2.12187846e+01, -1.70269254e+00],\n",
       "               [ 2.12518401e+01, -1.71263947e+00],\n",
       "               [-3.29625173e+00,  1.42771135e+01],\n",
       "               [-1.51697382e+01, -7.98339860e+00],\n",
       "               [-1.11351533e+00,  1.06406745e+01],\n",
       "               [-5.06307401e+00, -1.32687490e+01],\n",
       "               [ 2.30983806e+01, -8.84962966e+00],\n",
       "               [-1.47681527e+00,  7.14355908e+00],\n",
       "               [-9.54161132e+00, -1.56893048e+01],\n",
       "               [-1.09963453e+01,  3.22863286e+00],\n",
       "               [ 1.47190007e+00,  1.62428713e+01],\n",
       "               [-4.07712434e+00, -1.92791401e+01],\n",
       "               [ 7.01472844e+00, -1.02848269e+01],\n",
       "               [ 3.76940392e+00,  1.18297367e+01],\n",
       "               [ 1.31700755e+01,  6.75597680e+00],\n",
       "               [ 4.20502141e+00,  1.26150634e+01],\n",
       "               [ 9.48214354e+00,  4.79269236e+00],\n",
       "               [ 5.24516348e+00,  8.92367857e+00],\n",
       "               [ 1.83488182e+01, -8.41542257e+00],\n",
       "               [ 1.79364808e+01, -1.01007567e+01],\n",
       "               [-4.48651303e-01,  1.03541864e+01],\n",
       "               [-2.31999486e+01,  4.44357743e+00],\n",
       "               [ 1.70949427e+01, -2.24726471e+00],\n",
       "               [-1.02335088e+01, -8.91644566e+00],\n",
       "               [ 1.28259429e+01,  5.70778626e+00],\n",
       "               [-2.13190157e+01,  7.54887248e+00],\n",
       "               [-7.18326052e+00,  1.64683856e+01],\n",
       "               [-2.34194718e+00,  3.12591264e+00],\n",
       "               [-1.52647158e+01, -8.16939608e+00],\n",
       "               [ 2.63370319e+00,  6.31362327e+00],\n",
       "               [ 3.09449134e+00, -2.46794776e+00],\n",
       "               [ 1.68444045e+00, -4.86455079e+00],\n",
       "               [ 1.13339875e+01,  1.52520923e+01],\n",
       "               [ 7.19576850e+00, -2.79454144e+00],\n",
       "               [-7.68596988e+00, -1.56788633e+01],\n",
       "               [-1.86856761e+01, -1.18726384e+01],\n",
       "               [ 2.21316855e+01, -9.22336659e+00],\n",
       "               [-6.11212751e-01, -2.43852208e+00],\n",
       "               [ 3.82209849e+00,  2.03648266e+01],\n",
       "               [-1.27634576e+01, -8.41748250e+00],\n",
       "               [ 1.25850198e+01, -1.34177999e+01],\n",
       "               [ 1.06146824e+01,  7.64106431e+00],\n",
       "               [ 1.57733125e+01, -1.72696611e+01],\n",
       "               [-5.31448232e+00, -4.36249378e+00],\n",
       "               [ 1.73297283e+01, -6.90240290e+00],\n",
       "               [ 1.64760463e+01, -1.61441026e+01],\n",
       "               [ 4.14646815e+00,  1.43972301e+01],\n",
       "               [ 3.77525238e+00,  1.55646419e+01],\n",
       "               [ 1.50679165e+01, -7.86789185e+00],\n",
       "               [ 2.88733357e+00,  1.94605831e+01],\n",
       "               [ 8.23915153e-01, -6.58284450e-01],\n",
       "               [-7.42489401e-01,  1.67982050e+00],\n",
       "               [ 1.26017361e+01,  6.68018700e+00],\n",
       "               [ 1.66689924e+01, -8.92469071e+00],\n",
       "               [-1.20044176e+01, -8.56114484e+00],\n",
       "               [ 1.40676999e+01, -3.69347592e+00],\n",
       "               [ 2.63428591e+00, -5.15668169e+00],\n",
       "               [-6.96582194e+00, -1.67042137e+00],\n",
       "               [-5.04437162e+00,  1.06985932e+01],\n",
       "               [-1.28772597e+01, -5.92344233e-01],\n",
       "               [ 5.71482027e+00, -2.08513844e+00],\n",
       "               [-1.03610576e+00, -1.53592568e+01],\n",
       "               [ 1.16806610e+01,  5.47024022e+00],\n",
       "               [ 4.80601929e+00, -7.62938289e+00],\n",
       "               [ 1.03162295e+01,  4.18714295e+00],\n",
       "               [ 5.50782771e+00, -1.28009661e+01],\n",
       "               [-7.01827281e+00, -1.73127911e+01],\n",
       "               [ 1.45215219e+01, -1.18791956e+01],\n",
       "               [ 6.59072391e-01,  1.05658139e+01],\n",
       "               [-3.45465948e+00, -1.68574194e+00],\n",
       "               [ 2.18707694e+00, -1.58751105e+01],\n",
       "               [ 1.22065839e+01, -5.65011405e+00],\n",
       "               [-1.27570077e+01, -1.24735934e+01],\n",
       "               [-6.77507111e+00,  1.78542501e+01],\n",
       "               [-9.15442461e+00,  7.63908355e+00],\n",
       "               [ 3.74605513e+00, -1.50150546e+01],\n",
       "               [-1.52497627e+01, -3.22933466e+00],\n",
       "               [ 1.20841951e-01,  1.98454954e+00],\n",
       "               [ 9.48235230e+00, -1.49834860e+01],\n",
       "               [-3.68002627e+00,  1.39841286e+01],\n",
       "               [-5.35877480e+00, -8.30319565e-01],\n",
       "               [ 2.88523169e+00, -6.60444868e+00],\n",
       "               [ 3.92987042e+00,  1.49731234e+00],\n",
       "               [-9.96444972e+00, -1.69737162e+01],\n",
       "               [-2.22650707e+01,  6.56134987e+00],\n",
       "               [ 1.44012789e+01, -1.40870134e+01],\n",
       "               [-1.63303775e+00,  8.30184933e+00],\n",
       "               [-1.96752665e+01,  2.71469274e+00],\n",
       "               [ 1.61598173e+01, -5.21719136e+00],\n",
       "               [-6.00246027e+00, -1.09051245e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6604a-135d-45b2-b4ef-03795d9fbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, 1))\n",
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=np.zeros_like(x))\n",
    "    return z_star\n",
    "\n",
    "def fixed_point_layer_fwd(solver, f, params, x):\n",
    "    z_star = fixed_point_layer(solver, f, params, x)\n",
    "    return z_star, (params, x, z_star)\n",
    "\n",
    "def fixed_point_layer_bwd(solver, f, res, z_star_bar):\n",
    "    params, x, z_star = res\n",
    "    _, vjp_a = jax.vjp(lambda params, x: f(params, x, z_star), params, x)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(params, x, z), z_star)\n",
    "    return vjp_a(solver(lambda u: vjp_z(u)[0] + z_star_bar,\n",
    "                      z_init=np.zeros_like(z_star)))\n",
    "fixed_point_layer.defvjp(fixed_point_layer_fwd, fixed_point_layer_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df6b41a-35bb-45c8-9589-2610ec375197",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(n_samples=None):\n",
    "    with gzip.open(path.join(\"examples/data/mnist\", \"mnist.pkl.gz\"), \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    x, y = data[\"pca_50\"], data[\"labels\"]\n",
    "\n",
    "    if n_samples is not None:\n",
    "        indices = onp.random.choice(\n",
    "            list(range(x.shape[0])), n_samples, replace=False\n",
    "        )\n",
    "        x, y = x[indices], y[indices]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def compute_importances_per_sample(jacobian):\n",
    "    jacobian_sum_per_sample = []\n",
    "    jacobian_sum = np.sum(np.abs(jacobian), axis=0)\n",
    "    for i in range(n):\n",
    "        sum_for_sample = []\n",
    "        for j in range(p):\n",
    "            sum_for_sample.append(jacobian_sum[j*n+i])\n",
    "        jacobian_sum_per_sample.append(sum(sum_for_sample))\n",
    "    return jacobian_sum_per_sample\n",
    "\n",
    "def HdiffGreaterTrue(*betas):\n",
    "    beta, betamax = betas\n",
    "    return beta*2\n",
    "\n",
    "def HdiffGreaterFalse(*betas):\n",
    "    beta, betamax = betas\n",
    "    return (beta+betamax)/2\n",
    "\n",
    "def HdiffSmallerTrue(*betas):\n",
    "    beta, betamin = betas\n",
    "    return beta/2\n",
    "\n",
    "def HdiffSmallerFalse(*betas):\n",
    "    beta, betamin = betas\n",
    "    return (beta+betamin)/2\n",
    "\n",
    "def HdiffGreater(*betas):\n",
    "    beta, betamin, betamax = betas\n",
    "    betamin = beta\n",
    "    beta = cond((np.logical_or(betamax == np.inf, betamax == -np.inf)), HdiffGreaterTrue, HdiffGreaterFalse, *(beta, betamax))\n",
    "    return beta, betamin, betamax\n",
    "\n",
    "def HdiffSmaller(*betas):\n",
    "    beta, betamin, betamax = betas\n",
    "    betamax = beta\n",
    "    beta = cond(np.logical_or(betamin == np.inf, betamin == -np.inf), HdiffSmallerTrue, HdiffSmallerFalse, *(beta, betamin))\n",
    "    return beta, betamin, betamax\n",
    "\n",
    "def HdiffGreaterTolerance(*betas):\n",
    "    beta, betamin, betamax, Hdiff = betas\n",
    "    beta, betamin, betamax = cond(Hdiff > 0, HdiffGreater, HdiffSmaller, *(beta, betamin, betamax))\n",
    "    return beta, betamin, betamax, Hdiff\n",
    "\n",
    "\n",
    "def pca(X: np.ndarray, no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    #(n, d) = X.shape\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    u, s, vh = np.linalg.svd(X, full_matrices=False, compute_uv=True, hermitian=False)\n",
    "    #l = (s ** 2 / (d))[0:no_dims]\n",
    "    M = vh[0:no_dims, :]\n",
    "    Y = np.dot(X, M.T)\n",
    "    return Y\n",
    "\n",
    "def logSoftmax(x):\n",
    "    \"\"\"Compute softmax for vector x.\"\"\"\n",
    "    max_x = np.max(x)\n",
    "    exp_x = np.exp(x - max_x)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    log_sum_exp_x = np.log(sum_exp_x)\n",
    "    max_plus_log_sum_exp_x = max_x + log_sum_exp_x\n",
    "    log_probs = x - max_plus_log_sum_exp_x\n",
    "\n",
    "    # Recover probs\n",
    "    exp_log_probs = np.exp(log_probs)\n",
    "    sum_log_probs = np.sum(exp_log_probs)\n",
    "    probs = exp_log_probs / sum_log_probs\n",
    "    return probs\n",
    "\n",
    "\n",
    "def Hbeta(D: np.ndarray, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute the log2(perplexity)=Entropy and the P-row (P_i) for a specific value of the\n",
    "        precision=1/(sigma**2) (beta) of a Gaussian distribution. D: vector of squared Euclidean distances (without i)\n",
    "    :param D: vector of length d, squared Euclidean distances to all other datapoints (except itself)\n",
    "    :param beta: precision = beta = 1/sigma**2\n",
    "    :return: H: log2(Entropy), P: computed probabilites\n",
    "    \"\"\"\n",
    "    # TODO: exchange by softmax as described by https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/\n",
    "    P = np.exp(-D * beta)     # numerator of p j|i\n",
    "    sumP = np.sum(P, axis=None)    # denominator of p j|i --> normalization factor\n",
    "    new_P = logSoftmax(-D * beta)\n",
    "    sumP += 1e-8\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    return H, new_P\n",
    "\n",
    "def binarySearch(res, el, Di, logU):\n",
    "    print('Entered binary search function')\n",
    "    Hdiff, thisP, beta, betamin, betamax = res\n",
    "    Hdiffbool = np.abs(Hdiff) < 1e-5\n",
    "    beta, betamin, betamax, Hdiff = cond(np.abs(Hdiff) < 1e-5, lambda a, b, c, d: (a, b, c, d), HdiffGreaterTolerance, *(beta, betamin, betamax, Hdiff))\n",
    "\n",
    "    (H, thisP) = Hbeta(Di, beta)\n",
    "    Hdiff = H - logU\n",
    "    return (Hdiff, thisP, beta, betamin, betamax), el\n",
    "\n",
    "def x2p_inner(Di: np.ndarray, iterator, beta, betamin, betamax, perplexity=30, tol=1e-5):\n",
    "    \"\"\"\n",
    "    binary search for precision for Pi such that it matches the perplexity defined by the user\n",
    "    :param Di: vector of length d-1, squared Euclidean distances to all other datapoints (except itself)\n",
    "    :param beta: precision = beta = 1/sigma**2\n",
    "    :return: final probabilites p j|i\n",
    "    \"\"\"\n",
    "    # Compute the Gaussian kernel and entropy for the current precision\n",
    "    logU = np.log(perplexity)\n",
    "    H, thisP = Hbeta(Di, beta)\n",
    "    Hdiff = H - logU\n",
    "\n",
    "    print('Starting binary search')\n",
    "    binarySearch_func = partial(binarySearch, Di=Di, logU=logU)\n",
    "\n",
    "    # Note: the following binary Search for suitable precisions (betas) will be repeated 50 times and does not include the threshold value\n",
    "    (Hdiff, thisP, beta, betamin, betamax), el = scan(binarySearch_func, init=(Hdiff, thisP, beta, betamin, betamax), xs=None, length=50)    # Set the final row of P\n",
    "    thisP = np.insert(thisP, iterator, 0)\n",
    "    return thisP\n",
    "\n",
    "def x2p(X: np.ndarray, tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values (high-dim space) in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    D = np.reshape(np.delete(D, np.array([i for i in range(0, D.shape[0]**2, (D.shape[0]+1))])), (n , n - 1 ))\n",
    "    beta = np.ones(n)      # precisions (1/sigma**2)\n",
    "    betamin = np.full(n, -np.inf)\n",
    "    betamax = np.full(n, np.inf)\n",
    "    P = vmap(partial(x2p_inner, perplexity=perplexity, tol=tol))(D, np.arange(n), beta=beta, betamin=betamin, betamax=betamax)\n",
    "    return P\n",
    "\n",
    "def y2q(Y: np.ndarray):\n",
    "    # Compute pairwise affinities\n",
    "    sum_Y = np.sum(np.square(Y), 1)\n",
    "    num = -2. * np.dot(Y, Y.T)  # numerator\n",
    "    num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "    num = num.at[np.diag_indices_from(num)].set(0.)     # numerator\n",
    "    Q = num / np.sum(num)\n",
    "    Q = np.maximum(Q, 1e-12)\n",
    "    return Q\n",
    "\n",
    "def optimizeY(res, el, P, initial_momentum=0.5, final_momentum=0.8, eta=500, min_gain=0.01, exaggeration=4.):\n",
    "    Y, iY, gains, i = res\n",
    "    n, d = Y.shape\n",
    "\n",
    "    # Compute pairwise affinities\n",
    "    sum_Y = np.sum(np.square(Y), 1)\n",
    "    num = -2. * np.dot(Y, Y.T)  # numerator\n",
    "    num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "    num = num.at[np.diag_indices_from(num)].set(0.)     # numerator\n",
    "    Q = num / np.sum(num)\n",
    "    Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "\n",
    "    # Compute gradient\n",
    "    PQ = P - Q\n",
    "    PQ_exp = np.expand_dims(PQ, 2)  # NxNx1\n",
    "    Y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)  # nx1x2 - 1xnx2= # NxNx2\n",
    "    num_exp = np.expand_dims(num, 2)    # NxNx1\n",
    "    Y_diffs_wt = Y_diffs * num_exp\n",
    "    grad = np.sum((PQ_exp * Y_diffs_wt), axis=1) # Nx2\n",
    "\n",
    "    # Update Y\n",
    "    momentum = cond(i<250, lambda: initial_momentum, lambda: final_momentum)\n",
    "    # this business with \"gains\" is the bar-delta-bar heuristic to accelerate gradient descent\n",
    "    # code could be simplified by just omitting it\n",
    "    #inc = iY * grad > 0\n",
    "    #dec = iY * grad < 0\n",
    "    #gains = np.where((iY * grad > 0), gains+0.2, gains)\n",
    "    #gains = np.where((iY * grad < 0), gains*0.8, gains)\n",
    "    gains = np.clip(gains, min_gain, np.inf)\n",
    "\n",
    "    iY = momentum * iY - eta * (gains * grad)\n",
    "    Y = Y + iY\n",
    "\n",
    "    Y = Y - np.mean(Y, axis=0)\n",
    "    P = cond(i==100, lambda x: x/exaggeration, lambda x:x, P)\n",
    "    i += 1\n",
    "    return ((Y, iY, gains, i), 1.0)\n",
    "\n",
    "def optimizeYforBackprob(res, el, P, initial_momentum=0.8, final_momentum=0.5, eta=500, min_gain=0.01):\n",
    "    Y, iY, gains, i = res\n",
    "    n, d = Y.shape\n",
    "\n",
    "    # Compute pairwise affinities\n",
    "    sum_Y = stop_gradient(np.sum(np.square(Y), 1))\n",
    "    num = stop_gradient(-2. * np.dot(Y, Y.T))  # numerator\n",
    "    num = stop_gradient(1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y)))\n",
    "    num = stop_gradient(num.at[np.diag_indices_from(num)].set(0.))     # numerator\n",
    "    Q = stop_gradient(num / np.sum(num))\n",
    "    Q = stop_gradient(np.maximum(Q, 1e-12))\n",
    "\n",
    "\n",
    "    # Compute gradient\n",
    "    PQ = P - Q\n",
    "    PQ_exp = np.expand_dims(PQ, 2)  # NxNx1\n",
    "    Y_diffs = stop_gradient(np.expand_dims(Y, 1) - np.expand_dims(Y, 0))  # nx1x2 - 1xnx2= # NxNx2\n",
    "    num_exp = np.expand_dims(num, 2)    # NxNx1\n",
    "    Y_diffs_wt = stop_gradient(Y_diffs * num_exp)\n",
    "    grad = np.sum((PQ_exp * Y_diffs_wt), axis=1) # Nx2\n",
    "\n",
    "    # Update Y\n",
    "    momentum = cond(i<20, lambda: initial_momentum, lambda: final_momentum)\n",
    "    # this business with \"gains\" is the bar-delta-bar heuristic to accelerate gradient descent\n",
    "    # code could be simplified by just omitting it\n",
    "    # inc = iY * grad > 0\n",
    "    # dec = iY * grad < 0\n",
    "    # gains = np.where((iY * grad > 0), gains+0.2, gains)\n",
    "    # gains = np.where((iY * grad < 0), gains*0.8, gains)\n",
    "    gains = np.clip(gains, min_gain, np.inf)\n",
    "\n",
    "    iY = momentum * iY - eta * (gains * grad)\n",
    "    Y = Y + iY\n",
    "\n",
    "    Y = Y - np.mean(Y, axis=0)\n",
    "    P = cond(i==250, lambda x: x/12., lambda x:x, P)\n",
    "    i += 1\n",
    "    return ((Y, iY, gains, i), 1.0)\n",
    "\n",
    "def tsne(X: np.ndarray, no_dims=2, initial_dims=50, perplexity=30.0, learning_rate=500, max_iter = 1000, exaggeration=4., key=42):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    #X = pca(X, initial_dims)\n",
    "    (n, d) = X.shape\n",
    "    key = random.PRNGKey(key)\n",
    "\n",
    "    initial_momentum = 0.8\n",
    "    final_momentum = 0.5\n",
    "    eta = learning_rate   # Initial learning rate\n",
    "    min_gain = 0.01\n",
    "    # Initialize solution\n",
    "    #if init is not None:\n",
    "    #    Y = init\n",
    "    #else:\n",
    "    #    Y = random.normal(key, shape=(n, no_dims))\n",
    "    Y = random.normal(key, shape=(n, no_dims))\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    #Y_t1 = np.zeros((n, no_dims))\n",
    "    #Y_t2 = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)    # I don't know if the computed P is correct np.sum(P, axis=0) is not 1 everywhere\n",
    "    P = (P + np.transpose(P))\n",
    "\n",
    "    P = P / np.sum(P)      # Why don't we devide by 2N as described everywhere?\n",
    "    P = P * exaggeration  # early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # for debugging\n",
    "    #for i in range(1000):\n",
    "    #  ((P, Y, dY, iY, gains, i), j) = optimizeY((P, Y, dY, iY, gains, i), el=1, initial_momentum = initial_momentum, final_momentum = final_momentum, eta = eta, min_gain = min_gain)\n",
    "\n",
    "\n",
    "    # jit-compiled version\n",
    "    optimizeY_func = partial(optimizeY, P=P, initial_momentum = initial_momentum, final_momentum = final_momentum, eta = eta, min_gain = min_gain, exaggeration = exaggeration)\n",
    "    ((Y, iY, gains, i), el) = scan(optimizeY_func, init=(Y, iY, gains, 0), xs=None, length=max_iter)  # Set the final row of P\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009a552-3d3f-4df3-adb0-54a99663462a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "f = np.sum(P * (np.log(P+1e-10) - np.log(Q+1e-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e12310-77ba-4f58-918b-da9d9eeb8e4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def anderson_solver(f, z_init, m=5, lam=1e-4, max_iter=50, tol=1e-5, beta=1.0):\n",
    "    x0 = z_init\n",
    "    x1 = f(x0)\n",
    "    x2 = f(x1)\n",
    "    X = np.concatenate([np.stack([x0, x1]), np.zeros((m - 2, *np.shape(x0)))])\n",
    "    F = np.concatenate([np.stack([x1, x2]), np.zeros((m - 2, *np.shape(x0)))])\n",
    "\n",
    "    res = []\n",
    "    for k in range(2, max_iter):\n",
    "        n = min(k, m)\n",
    "        G = F[:n] - X[:n]\n",
    "        GTG = np.tensordot(G, G, [list(range(1, G.ndim))] * 2)\n",
    "        H = np.block([[np.zeros((1, 1)), np.ones((1, n))],\n",
    "                   [ np.ones((n, 1)), GTG]]) + lam * np.eye(n + 1)\n",
    "        alpha = np.linalg.solve(H, np.zeros(n+1).at[0].set(1))[1:]\n",
    "\n",
    "        xk = beta * np.dot(alpha, F[:n]) + (1-beta) * np.dot(alpha, X[:n])\n",
    "        X = X.at[k % m].set(xk)\n",
    "        F = F.at[k % m].set(f(xk))\n",
    "\n",
    "        res = np.linalg.norm(F[k % m] - X[k % m]) / (1e-5 + np.linalg.norm(F[k % m]))\n",
    "        if res < tol:\n",
    "            break\n",
    "    return xk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d8385e-2f73-41b7-85da-3780c7e96b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@partial(jax.custom_vjp, nondiff_argnums=(0, 1))\n",
    "def fixed_point_layer(solver, f, params, x):\n",
    "    z_star = solver(lambda z: f(params, x, z), z_init=np.zeros_like(x))\n",
    "    return z_star\n",
    "\n",
    "def fixed_point_layer_fwd(solver, f, params, x):\n",
    "    z_star = fixed_point_layer(solver, f, params, x)\n",
    "    return z_star, (params, x, z_star)\n",
    "\n",
    "def fixed_point_layer_bwd(solver, f, res, z_star_bar):\n",
    "    params, x, z_star = res\n",
    "    _, vjp_a = jax.vjp(lambda params, x: f(params, x, z_star), params, x)\n",
    "    _, vjp_z = jax.vjp(lambda z: f(params, x, z), z_star)\n",
    "    return vjp_a(solver(lambda u: vjp_z(u)[0] + z_star_bar,\n",
    "                      z_init=np.zeros_like(z_star)))\n",
    "fixed_point_layer.defvjp(fixed_point_layer_fwd, fixed_point_layer_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4fc9637-8fb9-48d3-b124-d4270b6b6dd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00752617 -0.8125575  -1.1404572  -0.04857638 -0.7125224  -0.55803984\n",
      "  0.66979057  1.1068186  -0.09697762  0.97838473]\n"
     ]
    }
   ],
   "source": [
    "f = lambda W, x, z: np.tanh(np.dot(W, z) + x)\n",
    "ndim = 10\n",
    "W = random.normal(random.PRNGKey(0), (ndim, ndim)) / np.sqrt(ndim)\n",
    "x = random.normal(random.PRNGKey(1), (ndim,))\n",
    "g = jax.grad(lambda W: fixed_point_layer(anderson_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0452314-bbc8-4caf-859f-c775350b4f52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00752136 -0.8125742  -1.1404786  -0.04860303 -0.7125376  -0.55805624\n",
      "  0.6697907   1.1068398  -0.09697363  0.9784083 ]\n"
     ]
    }
   ],
   "source": [
    "g = jax.grad(lambda W: fixed_point_layer(newton_solver, f, W, x).sum())(W)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f1bdf-54d3-4782-8092-44161cb7c98e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class gradient_descent:\n",
    "    def __init__(self):\n",
    "        self.gains = None\n",
    "\n",
    "    def copy(self):\n",
    "        optimizer = self.__class__()\n",
    "        if self.gains is not None:\n",
    "            optimizer.gains = np.copy(self.gains)\n",
    "        return optimizer\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        embedding,\n",
    "        P,\n",
    "        n_iter,\n",
    "        objective_function,\n",
    "        learning_rate=200,\n",
    "        momentum=0.5,\n",
    "        exaggeration=None,\n",
    "        dof=1,\n",
    "        min_gain=0.01,\n",
    "        max_grad_norm=None,\n",
    "        max_step_norm=5,\n",
    "        theta=0.5,\n",
    "        n_interpolation_points=3,\n",
    "        min_num_intervals=50,\n",
    "        ints_in_interval=1,\n",
    "        reference_embedding=None,\n",
    "        n_jobs=1,\n",
    "        use_callbacks=False,\n",
    "        callbacks=None,\n",
    "        callbacks_every_iters=50,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"Perform batch gradient descent with momentum and gains.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embedding: np.ndarray\n",
    "            The embedding :math:`Y`.\n",
    "\n",
    "        P: array_like\n",
    "            Joint probability matrix :math:`P`.\n",
    "\n",
    "        n_iter: int\n",
    "            The number of iterations to run for.\n",
    "\n",
    "        objective_function: Callable[..., Tuple[float, np.ndarray]]\n",
    "            A callable that evaluates the error and gradient for the current\n",
    "            embedding.\n",
    "\n",
    "        learning_rate: Union[str, float]\n",
    "            The learning rate for t-SNE optimization. When\n",
    "            ``learning_rate=\"auto\"`` the appropriate learning rate is selected\n",
    "            according to max(200, N / 12), as determined in Belkina et al.\n",
    "            \"Automated optimized parameters for t-distributed stochastic\n",
    "            neighbor embedding improve visualization and analysis of large\n",
    "            datasets\", 2019.\n",
    "\n",
    "        momentum: float\n",
    "            Momentum accounts for gradient directions from previous iterations,\n",
    "            resulting in faster convergence.\n",
    "\n",
    "        exaggeration: float\n",
    "            The exaggeration factor is used to increase the attractive forces of\n",
    "            nearby points, producing more compact clusters.\n",
    "\n",
    "        dof: float\n",
    "            Degrees of freedom of the Student's t-distribution.\n",
    "\n",
    "        min_gain: float\n",
    "            Minimum individual gain for each parameter.\n",
    "\n",
    "        max_grad_norm: float\n",
    "            Maximum gradient norm. If the norm exceeds this value, it will be\n",
    "            clipped. This is most beneficial when adding points into an existing\n",
    "            embedding and the new points overlap with the reference points,\n",
    "            leading to large gradients. This can make points \"shoot off\" from\n",
    "            the embedding, causing the interpolation method to compute a very\n",
    "            large grid, and leads to worse results.\n",
    "\n",
    "        max_step_norm: float\n",
    "            Maximum update norm. If the norm exceeds this value, it will be\n",
    "            clipped. This prevents points from \"shooting off\" from\n",
    "            the embedding.\n",
    "\n",
    "        theta: float\n",
    "            This is the trade-off parameter between speed and accuracy of the\n",
    "            tree approximation method. Typical values range from 0.2 to 0.8. The\n",
    "            value 0 indicates that no approximation is to be made and produces\n",
    "            exact results also producing longer runtime.\n",
    "\n",
    "        n_interpolation_points: int\n",
    "            Only used when ``negative_gradient_method=\"fft\"`` or its other\n",
    "            aliases. The number of interpolation points to use within each grid\n",
    "            cell for interpolation based t-SNE. It is highly recommended leaving\n",
    "            this value at the default 3.\n",
    "\n",
    "        min_num_intervals: int\n",
    "            Only used when ``negative_gradient_method=\"fft\"`` or its other\n",
    "            aliases. The minimum number of grid cells to use, regardless of the\n",
    "            ``ints_in_interval`` parameter. Higher values provide more accurate\n",
    "            gradient estimations.\n",
    "\n",
    "        ints_in_interval: float\n",
    "            Only used when ``negative_gradient_method=\"fft\"`` or its other\n",
    "            aliases. Indicates how large a grid cell should be e.g. a value of 3\n",
    "            indicates a grid side length of 3. Lower values provide more\n",
    "            accurate gradient estimations.\n",
    "\n",
    "        reference_embedding: np.ndarray\n",
    "            If we are adding points to an existing embedding, we have to compute\n",
    "            the gradients and errors w.r.t. the existing embedding.\n",
    "\n",
    "        n_jobs: int\n",
    "            The number of threads to use while running t-SNE. This follows the\n",
    "            scikit-learn convention, ``-1`` meaning all processors, ``-2``\n",
    "            meaning all but one, etc.\n",
    "\n",
    "        use_callbacks: bool\n",
    "\n",
    "        callbacks: Callable[[int, float, np.ndarray] -> bool]\n",
    "            Callbacks, which will be run every ``callbacks_every_iters``\n",
    "            iterations.\n",
    "\n",
    "        callbacks_every_iters: int\n",
    "            How many iterations should pass between each time the callbacks are\n",
    "            invoked.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The KL divergence of the optimized embedding.\n",
    "        np.ndarray\n",
    "            The optimized embedding Y.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        OptimizationInterrupt\n",
    "            If the provided callback interrupts the optimization, this is raised.\n",
    "\n",
    "        \"\"\"\n",
    "        assert isinstance(embedding, np.ndarray), (\n",
    "            \"`embedding` must be an instance of `np.ndarray`. Got `%s` instead\"\n",
    "            % type(embedding)\n",
    "        )\n",
    "\n",
    "        if reference_embedding is not None:\n",
    "            assert isinstance(reference_embedding, np.ndarray), (\n",
    "                \"`reference_embedding` must be an instance of `np.ndarray`. Got \"\n",
    "                \"`%s` instead\" % type(reference_embedding)\n",
    "            )\n",
    "\n",
    "        # If the interpolation grid has not yet been evaluated, do it now\n",
    "        if (\n",
    "            reference_embedding is not None and\n",
    "            reference_embedding.interp_coeffs is None and\n",
    "            objective_function is kl_divergence_fft\n",
    "        ):\n",
    "            reference_embedding.prepare_interpolation_grid()\n",
    "\n",
    "        # If we're running transform and using the interpolation scheme, then we\n",
    "        # should limit the range where new points can go to\n",
    "        should_limit_range = False\n",
    "        if reference_embedding is not None:\n",
    "            if reference_embedding.box_x_lower_bounds is not None:\n",
    "                should_limit_range = True\n",
    "                lower_limit = reference_embedding.box_x_lower_bounds[0]\n",
    "                upper_limit = reference_embedding.box_x_lower_bounds[-1]\n",
    "\n",
    "        update = np.zeros_like(embedding)\n",
    "        if self.gains is None:\n",
    "            self.gains = np.ones_like(embedding).view(np.ndarray)\n",
    "\n",
    "        bh_params = {\"theta\": theta}\n",
    "        fft_params = {\n",
    "            \"n_interpolation_points\": n_interpolation_points,\n",
    "            \"min_num_intervals\": min_num_intervals,\n",
    "            \"ints_in_interval\": ints_in_interval,\n",
    "        }\n",
    "\n",
    "        # Lie about the P values for bigger attraction forces\n",
    "        if exaggeration is None:\n",
    "            exaggeration = 1\n",
    "\n",
    "        if exaggeration != 1:\n",
    "            P *= exaggeration\n",
    "\n",
    "        # Notify the callbacks that the optimization is about to start\n",
    "        if isinstance(callbacks, Iterable):\n",
    "            for callback in callbacks:\n",
    "                # Only call function if present on object\n",
    "                getattr(callback, \"optimization_about_to_start\", lambda: ...)()\n",
    "\n",
    "        timer = utils.Timer(\n",
    "            \"Running optimization with exaggeration=%.2f, lr=%.2f for %d iterations...\" % (\n",
    "                exaggeration, learning_rate, n_iter\n",
    "            ),\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        timer.__enter__()\n",
    "\n",
    "        if verbose:\n",
    "            start_time = time()\n",
    "\n",
    "        for iteration in range(n_iter):\n",
    "            should_call_callback = use_callbacks and (iteration + 1) % callbacks_every_iters == 0\n",
    "            # Evaluate error on 50 iterations for logging, or when callbacks\n",
    "            should_eval_error = should_call_callback or \\\n",
    "                (verbose and (iteration + 1) % 50 == 0)\n",
    "\n",
    "            error, gradient = objective_function(\n",
    "                embedding,\n",
    "                P,\n",
    "                dof=dof,\n",
    "                bh_params=bh_params,\n",
    "                fft_params=fft_params,\n",
    "                reference_embedding=reference_embedding,\n",
    "                n_jobs=n_jobs,\n",
    "                should_eval_error=should_eval_error,\n",
    "            )\n",
    "\n",
    "            # Clip gradients to avoid points shooting off. This can be an issue\n",
    "            # when applying transform and points are initialized so that the new\n",
    "            # points overlap with the reference points, leading to large\n",
    "            # gradients\n",
    "            if max_grad_norm is not None:\n",
    "                norm = np.linalg.norm(gradient, axis=1)\n",
    "                coeff = max_grad_norm / (norm + 1e-6)\n",
    "                mask = coeff < 1\n",
    "                gradient[mask] *= coeff[mask, None]\n",
    "\n",
    "            # Correct the KL divergence w.r.t. the exaggeration if needed\n",
    "            if should_eval_error and exaggeration != 1:\n",
    "                error = error / exaggeration - np.log(exaggeration)\n",
    "\n",
    "            if should_call_callback:\n",
    "                # Continue only if all the callbacks say so\n",
    "                should_stop = any(\n",
    "                    (bool(c(iteration + 1, error, embedding)) for c in callbacks)\n",
    "                )\n",
    "                if should_stop:\n",
    "                    # Make sure to un-exaggerate P so it's not corrupted in future runs\n",
    "                    if exaggeration != 1:\n",
    "                        P /= exaggeration\n",
    "                    raise OptimizationInterrupt(error=error, final_embedding=embedding)\n",
    "\n",
    "            # Update the embedding using the gradient\n",
    "            grad_direction_flipped = np.sign(update) != np.sign(gradient)\n",
    "            grad_direction_same = np.invert(grad_direction_flipped)\n",
    "            self.gains[grad_direction_flipped] += 0.2\n",
    "            self.gains[grad_direction_same] = (\n",
    "                self.gains[grad_direction_same] * 0.8 + min_gain\n",
    "            )\n",
    "            update = momentum * update - learning_rate * self.gains * gradient\n",
    "\n",
    "            # Clip the update sizes\n",
    "            if max_step_norm is not None:\n",
    "                update_norms = np.linalg.norm(update, axis=1, keepdims=True)\n",
    "                mask = update_norms.squeeze() > max_step_norm\n",
    "                update[mask] /= update_norms[mask]\n",
    "                update[mask] *= max_step_norm\n",
    "\n",
    "            embedding += update\n",
    "\n",
    "            # Zero-mean the embedding only if we're not adding new data points,\n",
    "            # otherwise this will reset point positions\n",
    "            if reference_embedding is None:\n",
    "                embedding -= np.mean(embedding, axis=0)\n",
    "\n",
    "            # Limit any new points within the circle defined by the interpolation grid\n",
    "            if should_limit_range:\n",
    "                if embedding.shape[1] == 1:\n",
    "                    mask = (embedding < lower_limit) | (embedding > upper_limit)\n",
    "                    np.clip(embedding, lower_limit, upper_limit, out=embedding)\n",
    "                elif embedding.shape[1] == 2:\n",
    "                    r_limit = max(abs(lower_limit), abs(upper_limit))\n",
    "                    embedding, mask = utils.clip_point_to_disc(embedding, r_limit, inplace=True)\n",
    "\n",
    "                # Zero out the momentum terms for the points that hit the boundary\n",
    "                self.gains[~mask] = 0\n",
    "\n",
    "            if verbose and (iteration + 1) % 50 == 0:\n",
    "                stop_time = time()\n",
    "                print(\"Iteration %4d, KL divergence %6.4f, 50 iterations in %.4f sec\" % (\n",
    "                    iteration + 1, error, stop_time - start_time))\n",
    "                start_time = time()\n",
    "\n",
    "        timer.__exit__()\n",
    "\n",
    "        # Make sure to un-exaggerate P so it's not corrupted in future runs\n",
    "        if exaggeration != 1:\n",
    "            P /= exaggeration\n",
    "\n",
    "        # The error from the loop is the one for the previous, non-updated\n",
    "        # embedding. We need to return the error for the actual final embedding, so\n",
    "        # compute that at the end before returning\n",
    "        error, _ = objective_function(\n",
    "            embedding,\n",
    "            P,\n",
    "            dof=dof,\n",
    "            bh_params=bh_params,\n",
    "            fft_params=fft_params,\n",
    "            reference_embedding=reference_embedding,\n",
    "            n_jobs=n_jobs,\n",
    "            should_eval_error=True,\n",
    "        )\n",
    "\n",
    "        return error, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18790f78-161c-4bef-9ae8-b77dead358de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lax import custom_root\n",
    "\n",
    "def KL_gradient(Y, theta):\n",
    "    '''\n",
    "    computes gradient of the KL-divergence D_KL(P(X)||Q(Y))\n",
    "    '''\n",
    "    momentum, learning_rate, perplexity, X = theta\n",
    "    P = x2p(X, tol=1e-5, perplexity=perplexity)\n",
    "    Q = y2q(Y)\n",
    "    PQ = P - Q\n",
    "    PQ_exp = np.expand_dims(PQ, 2)  # NxNx1\n",
    "    Y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)  # nx1x2 - 1xnx2= # NxNx2\n",
    "    num_exp = np.expand_dims(num, 2)    # NxNx1\n",
    "    Y_diffs_wt = Y_diffs * num_exp\n",
    "    return np.sum((PQ_exp * Y_diffs_wt), axis=1) # Nx2\n",
    "    \n",
    "    \n",
    "def T(Y, theta):\n",
    "    momentum, learning_rate, perplexity, X = theta\n",
    "    # only gradient\n",
    "    return Y - learning_rate * KL_gradient(Y, theta)\n",
    "    #return Y + momentum * update - learning_rate * self.gains * gradient(Y, x)\n",
    "\n",
    "def tsne(init_Y, theta):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "    momentum, learning_rate, perplexity, X = theta\n",
    "    no_dims=2\n",
    "    initial_dims=50\n",
    "    max_iter = 1000\n",
    "    exaggeration=4.\n",
    "    key=42\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    #X = pca(X, initial_dims)\n",
    "    (n, d) = X.shape\n",
    "    key = random.PRNGKey(key)\n",
    "\n",
    "    initial_momentum = 0.8\n",
    "    final_momentum = 0.5\n",
    "    eta = learning_rate   # Initial learning rate\n",
    "    min_gain = 0.01\n",
    "    # Initialize solution\n",
    "    #if init is not None:\n",
    "    #    Y = init\n",
    "    #else:\n",
    "    #    Y = random.normal(key, shape=(n, no_dims))\n",
    "    Y = random.normal(key, shape=(n, no_dims))\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    #Y_t1 = np.zeros((n, no_dims))\n",
    "    #Y_t2 = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)    # I don't know if the computed P is correct np.sum(P, axis=0) is not 1 everywhere\n",
    "    P = (P + np.transpose(P))\n",
    "\n",
    "    P = P / np.sum(P)      # Why don't we devide by 2N as described everywhere?\n",
    "    P = P * exaggeration  # early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # for debugging\n",
    "    #for i in range(1000):\n",
    "    #  ((P, Y, dY, iY, gains, i), j) = optimizeY((P, Y, dY, iY, gains, i), el=1, initial_momentum = initial_momentum, final_momentum = final_momentum, eta = eta, min_gain = min_gain)\n",
    "\n",
    "\n",
    "    # jit-compiled version\n",
    "    optimizeY_func = partial(optimizeY, P=P, initial_momentum = initial_momentum, final_momentum = final_momentum, eta = eta, min_gain = min_gain, exaggeration = exaggeration)\n",
    "    ((Y, iY, gains, i), el) = scan(optimizeY_func, init=(Y, iY, gains, 0), xs=None, length=max_iter)  # Set the final row of P\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61874f6f-b7d4-448b-9ac9-20425479c5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
